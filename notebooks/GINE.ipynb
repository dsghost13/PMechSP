{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:28:59.260548Z",
     "start_time": "2025-11-22T07:28:52.467696Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from scripts.data_formatting import SmilesDataset\n",
    "from scripts.downstream import get_prediction_smiles, split_batch_by_molecule\n",
    "from scripts.nn_models import GINE"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "ae6f9835a62a1d5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:28:59.293793Z",
     "start_time": "2025-11-22T07:28:59.275036Z"
    }
   },
   "source": [
    "# raw dataset\n",
    "df = pd.read_csv('../datasets/13k_All_Manual.csv')\n",
    "smiles_list = df['SMILES Labelled'].tolist()"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "ced30a7c1f93e96f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:29:08.068306Z",
     "start_time": "2025-11-22T07:28:59.301273Z"
    }
   },
   "source": [
    "# 70/15/15 train/test/val split\n",
    "train_smiles, test_smiles = train_test_split(smiles_list, test_size=0.15, random_state=42)\n",
    "train_smiles, val_smiles = train_test_split(train_smiles, test_size=0.1765, random_state=42)\n",
    "\n",
    "# dataset objects\n",
    "train_dataset = SmilesDataset(train_smiles)\n",
    "test_dataset  = SmilesDataset(test_smiles)\n",
    "val_dataset   = SmilesDataset(val_smiles)\n",
    "\n",
    "# dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ff6f6b800cf8f569",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T07:29:08.234307Z",
     "start_time": "2025-11-22T07:29:08.177450Z"
    }
   },
   "source": [
    "# model instance\n",
    "model = GINE(input_dim=9, hidden_dim=128, output_dim=5, edge_dim=8, num_layers=3)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T08:56:54.687429Z",
     "start_time": "2025-11-22T07:29:31.227975Z"
    }
   },
   "cell_type": "code",
   "source": [
    "counter = 0\n",
    "patience = 20\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # training\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = criterion(out, batch.y.argmax(dim=1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # validation\n",
    "    model.eval()\n",
    "    val_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "            loss = criterion(out, batch.y.argmax(dim=1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            preds, true = split_batch_by_molecule(out, batch)\n",
    "            for p, t in zip(preds, true):\n",
    "                if torch.equal(p, t):\n",
    "                    correct += 1\n",
    "                total += 1\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "    # validation accuracy\n",
    "    val_acc = correct / total\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val Acc: {val_acc*100:.2f}%\")\n",
    "\n",
    "    # early stopping\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        counter = 0\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), f\"../models/gine/gine_{epoch+1}.pt\")\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f\"Training stopped at epoch {epoch+1}.\")\n",
    "            break"
   ],
   "id": "c381275b5ea55ac1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.3456 | Val Loss: 0.3235 | Val Acc: 30.04%\n",
      "Epoch 2 | Train Loss: 0.3246 | Val Loss: 0.3049 | Val Acc: 33.35%\n",
      "Epoch 3 | Train Loss: 0.3051 | Val Loss: 0.3204 | Val Acc: 32.01%\n",
      "Epoch 4 | Train Loss: 0.2891 | Val Loss: 0.2732 | Val Acc: 38.64%\n",
      "Epoch 5 | Train Loss: 0.2712 | Val Loss: 0.2896 | Val Acc: 36.93%\n",
      "Epoch 6 | Train Loss: 0.2647 | Val Loss: 0.2499 | Val Acc: 40.67%\n",
      "Epoch 7 | Train Loss: 0.2541 | Val Loss: 0.2465 | Val Acc: 43.93%\n",
      "Epoch 8 | Train Loss: 0.2430 | Val Loss: 0.2412 | Val Acc: 42.22%\n",
      "Epoch 9 | Train Loss: 0.2341 | Val Loss: 0.2455 | Val Acc: 46.39%\n",
      "Epoch 10 | Train Loss: 0.2344 | Val Loss: 0.2230 | Val Acc: 46.29%\n",
      "Epoch 11 | Train Loss: 0.2221 | Val Loss: 0.2087 | Val Acc: 48.69%\n",
      "Epoch 12 | Train Loss: 0.2228 | Val Loss: 0.2117 | Val Acc: 48.58%\n",
      "Epoch 13 | Train Loss: 0.2124 | Val Loss: 0.2106 | Val Acc: 48.53%\n",
      "Epoch 14 | Train Loss: 0.2088 | Val Loss: 0.2087 | Val Acc: 48.26%\n",
      "Epoch 15 | Train Loss: 0.2015 | Val Loss: 0.1976 | Val Acc: 53.02%\n",
      "Epoch 16 | Train Loss: 0.1960 | Val Loss: 0.1884 | Val Acc: 52.81%\n",
      "Epoch 17 | Train Loss: 0.1940 | Val Loss: 0.1902 | Val Acc: 51.47%\n",
      "Epoch 18 | Train Loss: 0.1899 | Val Loss: 0.1990 | Val Acc: 53.13%\n",
      "Epoch 19 | Train Loss: 0.1903 | Val Loss: 0.1888 | Val Acc: 51.10%\n",
      "Epoch 20 | Train Loss: 0.1874 | Val Loss: 0.1759 | Val Acc: 54.78%\n",
      "Epoch 21 | Train Loss: 0.1813 | Val Loss: 0.1814 | Val Acc: 53.29%\n",
      "Epoch 22 | Train Loss: 0.1797 | Val Loss: 0.1774 | Val Acc: 55.26%\n",
      "Epoch 23 | Train Loss: 0.1774 | Val Loss: 0.1766 | Val Acc: 55.96%\n",
      "Epoch 24 | Train Loss: 0.1781 | Val Loss: 0.1787 | Val Acc: 57.30%\n",
      "Epoch 25 | Train Loss: 0.1737 | Val Loss: 0.1755 | Val Acc: 58.31%\n",
      "Epoch 26 | Train Loss: 0.1726 | Val Loss: 0.1795 | Val Acc: 57.08%\n",
      "Epoch 27 | Train Loss: 0.1694 | Val Loss: 0.1752 | Val Acc: 57.67%\n",
      "Epoch 28 | Train Loss: 0.1678 | Val Loss: 0.1652 | Val Acc: 57.51%\n",
      "Epoch 29 | Train Loss: 0.1653 | Val Loss: 0.1589 | Val Acc: 59.11%\n",
      "Epoch 30 | Train Loss: 0.1654 | Val Loss: 0.1654 | Val Acc: 59.65%\n",
      "Epoch 31 | Train Loss: 0.1616 | Val Loss: 0.1595 | Val Acc: 58.31%\n",
      "Epoch 32 | Train Loss: 0.1601 | Val Loss: 0.1575 | Val Acc: 60.88%\n",
      "Epoch 33 | Train Loss: 0.1575 | Val Loss: 0.1581 | Val Acc: 61.89%\n",
      "Epoch 34 | Train Loss: 0.1550 | Val Loss: 0.1569 | Val Acc: 58.15%\n",
      "Epoch 35 | Train Loss: 0.1566 | Val Loss: 0.1526 | Val Acc: 57.30%\n",
      "Epoch 36 | Train Loss: 0.1531 | Val Loss: 0.1644 | Val Acc: 59.59%\n",
      "Epoch 37 | Train Loss: 0.1561 | Val Loss: 0.1521 | Val Acc: 60.56%\n",
      "Epoch 38 | Train Loss: 0.1513 | Val Loss: 0.1590 | Val Acc: 60.56%\n",
      "Epoch 39 | Train Loss: 0.1494 | Val Loss: 0.1451 | Val Acc: 62.75%\n",
      "Epoch 40 | Train Loss: 0.1463 | Val Loss: 0.1453 | Val Acc: 62.91%\n",
      "Epoch 41 | Train Loss: 0.1447 | Val Loss: 0.1461 | Val Acc: 63.01%\n",
      "Epoch 42 | Train Loss: 0.1450 | Val Loss: 0.1485 | Val Acc: 61.95%\n",
      "Epoch 43 | Train Loss: 0.1437 | Val Loss: 0.1442 | Val Acc: 61.41%\n",
      "Epoch 44 | Train Loss: 0.1414 | Val Loss: 0.1462 | Val Acc: 62.37%\n",
      "Epoch 45 | Train Loss: 0.1406 | Val Loss: 0.1456 | Val Acc: 61.89%\n",
      "Epoch 46 | Train Loss: 0.1395 | Val Loss: 0.1459 | Val Acc: 63.82%\n",
      "Epoch 47 | Train Loss: 0.1381 | Val Loss: 0.1434 | Val Acc: 63.07%\n",
      "Epoch 48 | Train Loss: 0.1361 | Val Loss: 0.1398 | Val Acc: 65.15%\n",
      "Epoch 49 | Train Loss: 0.1368 | Val Loss: 0.1393 | Val Acc: 61.79%\n",
      "Epoch 50 | Train Loss: 0.1362 | Val Loss: 0.1409 | Val Acc: 63.55%\n",
      "Epoch 51 | Train Loss: 0.1333 | Val Loss: 0.1373 | Val Acc: 66.17%\n",
      "Epoch 52 | Train Loss: 0.1329 | Val Loss: 0.1396 | Val Acc: 63.87%\n",
      "Epoch 53 | Train Loss: 0.1325 | Val Loss: 0.1461 | Val Acc: 64.56%\n",
      "Epoch 54 | Train Loss: 0.1312 | Val Loss: 0.1476 | Val Acc: 62.37%\n",
      "Epoch 55 | Train Loss: 0.1304 | Val Loss: 0.1485 | Val Acc: 65.10%\n",
      "Epoch 56 | Train Loss: 0.1307 | Val Loss: 0.1511 | Val Acc: 61.46%\n",
      "Epoch 57 | Train Loss: 0.1284 | Val Loss: 0.1330 | Val Acc: 62.16%\n",
      "Epoch 58 | Train Loss: 0.1275 | Val Loss: 0.1386 | Val Acc: 65.69%\n",
      "Epoch 59 | Train Loss: 0.1271 | Val Loss: 0.1483 | Val Acc: 63.12%\n",
      "Epoch 60 | Train Loss: 0.1264 | Val Loss: 0.1395 | Val Acc: 63.07%\n",
      "Epoch 61 | Train Loss: 0.1243 | Val Loss: 0.1311 | Val Acc: 66.97%\n",
      "Epoch 62 | Train Loss: 0.1241 | Val Loss: 0.1308 | Val Acc: 64.08%\n",
      "Epoch 63 | Train Loss: 0.1239 | Val Loss: 0.1312 | Val Acc: 66.76%\n",
      "Epoch 64 | Train Loss: 0.1226 | Val Loss: 0.1318 | Val Acc: 66.44%\n",
      "Epoch 65 | Train Loss: 0.1229 | Val Loss: 0.1399 | Val Acc: 65.31%\n",
      "Epoch 66 | Train Loss: 0.1216 | Val Loss: 0.1313 | Val Acc: 67.18%\n",
      "Epoch 67 | Train Loss: 0.1236 | Val Loss: 0.1356 | Val Acc: 65.95%\n",
      "Epoch 68 | Train Loss: 0.1213 | Val Loss: 0.1380 | Val Acc: 64.24%\n",
      "Epoch 69 | Train Loss: 0.1203 | Val Loss: 0.1282 | Val Acc: 68.73%\n",
      "Epoch 70 | Train Loss: 0.1201 | Val Loss: 0.1264 | Val Acc: 66.38%\n",
      "Epoch 71 | Train Loss: 0.1176 | Val Loss: 0.1264 | Val Acc: 67.45%\n",
      "Epoch 72 | Train Loss: 0.1192 | Val Loss: 0.1271 | Val Acc: 67.77%\n",
      "Epoch 73 | Train Loss: 0.1178 | Val Loss: 0.1267 | Val Acc: 67.99%\n",
      "Epoch 74 | Train Loss: 0.1162 | Val Loss: 0.1252 | Val Acc: 67.82%\n",
      "Epoch 75 | Train Loss: 0.1158 | Val Loss: 0.1226 | Val Acc: 66.97%\n",
      "Epoch 76 | Train Loss: 0.1144 | Val Loss: 0.1246 | Val Acc: 67.82%\n",
      "Epoch 77 | Train Loss: 0.1150 | Val Loss: 0.1194 | Val Acc: 68.20%\n",
      "Epoch 78 | Train Loss: 0.1145 | Val Loss: 0.1311 | Val Acc: 66.06%\n",
      "Epoch 79 | Train Loss: 0.1144 | Val Loss: 0.1251 | Val Acc: 66.76%\n",
      "Epoch 80 | Train Loss: 0.1139 | Val Loss: 0.1221 | Val Acc: 67.56%\n",
      "Epoch 81 | Train Loss: 0.1153 | Val Loss: 0.1212 | Val Acc: 68.47%\n",
      "Epoch 82 | Train Loss: 0.1104 | Val Loss: 0.1336 | Val Acc: 65.10%\n",
      "Epoch 83 | Train Loss: 0.1132 | Val Loss: 0.1231 | Val Acc: 69.37%\n",
      "Epoch 84 | Train Loss: 0.1106 | Val Loss: 0.1214 | Val Acc: 69.00%\n",
      "Epoch 85 | Train Loss: 0.1109 | Val Loss: 0.1210 | Val Acc: 67.61%\n",
      "Epoch 86 | Train Loss: 0.1103 | Val Loss: 0.1223 | Val Acc: 67.77%\n",
      "Epoch 87 | Train Loss: 0.1098 | Val Loss: 0.1246 | Val Acc: 69.43%\n",
      "Epoch 88 | Train Loss: 0.1111 | Val Loss: 0.1174 | Val Acc: 69.80%\n",
      "Epoch 89 | Train Loss: 0.1102 | Val Loss: 0.1273 | Val Acc: 68.63%\n",
      "Epoch 90 | Train Loss: 0.1090 | Val Loss: 0.1197 | Val Acc: 69.75%\n",
      "Epoch 91 | Train Loss: 0.1077 | Val Loss: 0.1206 | Val Acc: 69.32%\n",
      "Epoch 92 | Train Loss: 0.1096 | Val Loss: 0.1292 | Val Acc: 67.40%\n",
      "Epoch 93 | Train Loss: 0.1083 | Val Loss: 0.1237 | Val Acc: 66.38%\n",
      "Epoch 94 | Train Loss: 0.1057 | Val Loss: 0.1253 | Val Acc: 68.15%\n",
      "Epoch 95 | Train Loss: 0.1087 | Val Loss: 0.1211 | Val Acc: 69.54%\n",
      "Epoch 96 | Train Loss: 0.1055 | Val Loss: 0.1149 | Val Acc: 70.34%\n",
      "Epoch 97 | Train Loss: 0.1048 | Val Loss: 0.1280 | Val Acc: 68.25%\n",
      "Epoch 98 | Train Loss: 0.1051 | Val Loss: 0.1191 | Val Acc: 66.92%\n",
      "Epoch 99 | Train Loss: 0.1051 | Val Loss: 0.1200 | Val Acc: 68.47%\n",
      "Epoch 100 | Train Loss: 0.1047 | Val Loss: 0.1224 | Val Acc: 68.04%\n",
      "Epoch 101 | Train Loss: 0.1055 | Val Loss: 0.1150 | Val Acc: 68.84%\n",
      "Epoch 102 | Train Loss: 0.1047 | Val Loss: 0.1192 | Val Acc: 70.18%\n",
      "Epoch 103 | Train Loss: 0.1038 | Val Loss: 0.1177 | Val Acc: 68.36%\n",
      "Epoch 104 | Train Loss: 0.1043 | Val Loss: 0.1138 | Val Acc: 70.60%\n",
      "Epoch 105 | Train Loss: 0.1022 | Val Loss: 0.1151 | Val Acc: 69.91%\n",
      "Epoch 106 | Train Loss: 0.1022 | Val Loss: 0.1197 | Val Acc: 71.03%\n",
      "Epoch 107 | Train Loss: 0.1004 | Val Loss: 0.1159 | Val Acc: 70.76%\n",
      "Epoch 108 | Train Loss: 0.1017 | Val Loss: 0.1155 | Val Acc: 68.15%\n",
      "Epoch 109 | Train Loss: 0.1001 | Val Loss: 0.1152 | Val Acc: 69.43%\n",
      "Epoch 110 | Train Loss: 0.0999 | Val Loss: 0.1183 | Val Acc: 70.28%\n",
      "Epoch 111 | Train Loss: 0.1011 | Val Loss: 0.1151 | Val Acc: 70.44%\n",
      "Epoch 112 | Train Loss: 0.1014 | Val Loss: 0.1182 | Val Acc: 69.80%\n",
      "Epoch 113 | Train Loss: 0.0995 | Val Loss: 0.1137 | Val Acc: 68.79%\n",
      "Epoch 114 | Train Loss: 0.0982 | Val Loss: 0.1138 | Val Acc: 70.12%\n",
      "Epoch 115 | Train Loss: 0.0988 | Val Loss: 0.1139 | Val Acc: 69.16%\n",
      "Epoch 116 | Train Loss: 0.0996 | Val Loss: 0.1159 | Val Acc: 69.64%\n",
      "Epoch 117 | Train Loss: 0.0988 | Val Loss: 0.1111 | Val Acc: 70.55%\n",
      "Epoch 118 | Train Loss: 0.0990 | Val Loss: 0.1144 | Val Acc: 70.82%\n",
      "Epoch 119 | Train Loss: 0.0970 | Val Loss: 0.1107 | Val Acc: 69.70%\n",
      "Epoch 120 | Train Loss: 0.0968 | Val Loss: 0.1104 | Val Acc: 68.36%\n",
      "Epoch 121 | Train Loss: 0.0979 | Val Loss: 0.1132 | Val Acc: 70.02%\n",
      "Epoch 122 | Train Loss: 0.0962 | Val Loss: 0.1110 | Val Acc: 68.04%\n",
      "Epoch 123 | Train Loss: 0.0975 | Val Loss: 0.1126 | Val Acc: 68.15%\n",
      "Epoch 124 | Train Loss: 0.0957 | Val Loss: 0.1105 | Val Acc: 70.39%\n",
      "Epoch 125 | Train Loss: 0.0973 | Val Loss: 0.1120 | Val Acc: 70.87%\n",
      "Epoch 126 | Train Loss: 0.0950 | Val Loss: 0.1138 | Val Acc: 69.21%\n",
      "Epoch 127 | Train Loss: 0.0965 | Val Loss: 0.1089 | Val Acc: 70.23%\n",
      "Epoch 128 | Train Loss: 0.0952 | Val Loss: 0.1156 | Val Acc: 68.79%\n",
      "Epoch 129 | Train Loss: 0.0965 | Val Loss: 0.1142 | Val Acc: 70.92%\n",
      "Epoch 130 | Train Loss: 0.0942 | Val Loss: 0.1127 | Val Acc: 71.41%\n",
      "Epoch 131 | Train Loss: 0.0942 | Val Loss: 0.1172 | Val Acc: 69.64%\n",
      "Epoch 132 | Train Loss: 0.0939 | Val Loss: 0.1146 | Val Acc: 70.82%\n",
      "Epoch 133 | Train Loss: 0.0951 | Val Loss: 0.1186 | Val Acc: 70.12%\n",
      "Epoch 134 | Train Loss: 0.0937 | Val Loss: 0.1160 | Val Acc: 70.71%\n",
      "Epoch 135 | Train Loss: 0.0945 | Val Loss: 0.1140 | Val Acc: 69.48%\n",
      "Epoch 136 | Train Loss: 0.0947 | Val Loss: 0.1097 | Val Acc: 70.44%\n",
      "Epoch 137 | Train Loss: 0.0932 | Val Loss: 0.1139 | Val Acc: 70.66%\n",
      "Epoch 138 | Train Loss: 0.0932 | Val Loss: 0.1123 | Val Acc: 71.41%\n",
      "Epoch 139 | Train Loss: 0.0929 | Val Loss: 0.1169 | Val Acc: 70.71%\n",
      "Epoch 140 | Train Loss: 0.0929 | Val Loss: 0.1108 | Val Acc: 71.89%\n",
      "Epoch 141 | Train Loss: 0.0918 | Val Loss: 0.1143 | Val Acc: 70.92%\n",
      "Epoch 142 | Train Loss: 0.0932 | Val Loss: 0.1081 | Val Acc: 71.62%\n",
      "Epoch 143 | Train Loss: 0.0920 | Val Loss: 0.1136 | Val Acc: 72.05%\n",
      "Epoch 144 | Train Loss: 0.0924 | Val Loss: 0.1107 | Val Acc: 69.59%\n",
      "Epoch 145 | Train Loss: 0.0908 | Val Loss: 0.1093 | Val Acc: 71.99%\n",
      "Epoch 146 | Train Loss: 0.0917 | Val Loss: 0.1106 | Val Acc: 70.02%\n",
      "Epoch 147 | Train Loss: 0.0906 | Val Loss: 0.1080 | Val Acc: 71.41%\n",
      "Epoch 148 | Train Loss: 0.0921 | Val Loss: 0.1060 | Val Acc: 70.28%\n",
      "Epoch 149 | Train Loss: 0.0904 | Val Loss: 0.1116 | Val Acc: 71.19%\n",
      "Epoch 150 | Train Loss: 0.0896 | Val Loss: 0.1113 | Val Acc: 68.25%\n",
      "Epoch 151 | Train Loss: 0.0911 | Val Loss: 0.1153 | Val Acc: 70.76%\n",
      "Epoch 152 | Train Loss: 0.0902 | Val Loss: 0.1106 | Val Acc: 71.08%\n",
      "Epoch 153 | Train Loss: 0.0889 | Val Loss: 0.1155 | Val Acc: 70.55%\n",
      "Epoch 154 | Train Loss: 0.0888 | Val Loss: 0.1058 | Val Acc: 71.57%\n",
      "Epoch 155 | Train Loss: 0.0883 | Val Loss: 0.1097 | Val Acc: 71.57%\n",
      "Epoch 156 | Train Loss: 0.0896 | Val Loss: 0.1050 | Val Acc: 71.99%\n",
      "Epoch 157 | Train Loss: 0.0890 | Val Loss: 0.1098 | Val Acc: 71.30%\n",
      "Epoch 158 | Train Loss: 0.0887 | Val Loss: 0.1099 | Val Acc: 69.54%\n",
      "Epoch 159 | Train Loss: 0.0907 | Val Loss: 0.1072 | Val Acc: 71.25%\n",
      "Epoch 160 | Train Loss: 0.0875 | Val Loss: 0.1108 | Val Acc: 71.41%\n",
      "Epoch 161 | Train Loss: 0.0875 | Val Loss: 0.1058 | Val Acc: 72.05%\n",
      "Epoch 162 | Train Loss: 0.0884 | Val Loss: 0.1084 | Val Acc: 71.94%\n",
      "Epoch 163 | Train Loss: 0.0876 | Val Loss: 0.1077 | Val Acc: 71.94%\n",
      "Epoch 164 | Train Loss: 0.0865 | Val Loss: 0.1119 | Val Acc: 69.96%\n",
      "Epoch 165 | Train Loss: 0.0872 | Val Loss: 0.1093 | Val Acc: 71.99%\n",
      "Epoch 166 | Train Loss: 0.0879 | Val Loss: 0.1095 | Val Acc: 70.28%\n",
      "Epoch 167 | Train Loss: 0.0890 | Val Loss: 0.1065 | Val Acc: 71.46%\n",
      "Epoch 168 | Train Loss: 0.0884 | Val Loss: 0.1098 | Val Acc: 73.22%\n",
      "Epoch 169 | Train Loss: 0.0865 | Val Loss: 0.1116 | Val Acc: 70.98%\n",
      "Epoch 170 | Train Loss: 0.0866 | Val Loss: 0.1108 | Val Acc: 71.46%\n",
      "Epoch 171 | Train Loss: 0.0850 | Val Loss: 0.1083 | Val Acc: 72.96%\n",
      "Epoch 172 | Train Loss: 0.0864 | Val Loss: 0.1070 | Val Acc: 70.87%\n",
      "Epoch 173 | Train Loss: 0.0863 | Val Loss: 0.1067 | Val Acc: 72.42%\n",
      "Epoch 174 | Train Loss: 0.0875 | Val Loss: 0.1128 | Val Acc: 69.75%\n",
      "Epoch 175 | Train Loss: 0.0862 | Val Loss: 0.1051 | Val Acc: 69.64%\n",
      "Epoch 176 | Train Loss: 0.0862 | Val Loss: 0.1066 | Val Acc: 69.75%\n",
      "Training stopped at epoch 176.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T09:27:11.064712Z",
     "start_time": "2025-11-22T09:27:05.925878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_PATH = '../models/gine/gine_156.pt'\n",
    "OUTPUT_CSV = '../results/gine_test_eval.csv'\n",
    "\n",
    "# load best model\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "\n",
    "smiles_original = []\n",
    "smiles_predicted = []\n",
    "smiles_matched = []\n",
    "\n",
    "# test evaluation\n",
    "model.eval()\n",
    "test_loss, correct, total = 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "        loss = criterion(out, batch.y.argmax(dim=1))\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        preds, true = split_batch_by_molecule(out, batch)\n",
    "        for p, t in zip(preds, true):\n",
    "            if torch.equal(p, t):\n",
    "                smiles_matched.append(True)\n",
    "                correct += 1\n",
    "            else:\n",
    "                smiles_matched.append(False)\n",
    "            total += 1\n",
    "\n",
    "        smiles_original.extend(batch.smiles)\n",
    "        smiles_predicted.extend(get_prediction_smiles(preds, batch.smiles))\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "test_acc = correct / total\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# saves test predictions to .csv file\n",
    "test_df = pd.DataFrame({\n",
    "    'SMILES Original': smiles_original,\n",
    "    'SMILES Predicted': smiles_predicted,\n",
    "    'SMILES Matched': smiles_matched\n",
    "})\n",
    "test_df.to_csv(OUTPUT_CSV, index=False)\n",
    "print(f\"Saved predictions to {OUTPUT_CSV}.\")"
   ],
   "id": "640e2bc88272ab6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.1121\n",
      "Test Accuracy: 72.55%\n",
      "Saved predictions to ../results/gine_test_eval.csv.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T12:36:43.403549Z",
     "start_time": "2025-11-21T12:36:43.400882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 10 correct: 84.48%\n",
    "# 11 correct: 96.25%\n",
    "# 20 correct: 91.97%\n",
    "# 21 correct: 88.92%"
   ],
   "id": "9840146f361fb896",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e0f95fb7c2f44fc3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
